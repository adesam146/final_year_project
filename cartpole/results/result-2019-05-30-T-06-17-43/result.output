Experience: 1
Using Optimal GP Model. No training being done.
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 0, disc loss: 1.958181810301529, policy loss: 1232.9431644325127
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 1, disc loss: 1.0536958690128833, policy loss: 2927.9618724679854
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 2, disc loss: 0.9875118040797111, policy loss: 3020.61100885036
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 3, disc loss: 0.835928027414627, policy loss: 3867.6912497923013
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 4, disc loss: 0.8706010526573298, policy loss: 4334.456702737543
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 5, disc loss: 0.7796375094006123, policy loss: 5869.683236695164
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 6, disc loss: 0.7901418779741922, policy loss: 5576.8678553268455
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 7, disc loss: 0.6418790653890156, policy loss: 7245.631871145995
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 8, disc loss: 0.665068726730663, policy loss: 7373.623830208891
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 9, disc loss: 0.6435115748776964, policy loss: 7558.912554234
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 10, disc loss: 0.5767539184588455, policy loss: 9083.84422009561
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 11, disc loss: 0.6358683431300329, policy loss: 7718.949078870646
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 12, disc loss: 0.5371451444351361, policy loss: 7993.7677214606565
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 13, disc loss: 0.5343627488782767, policy loss: 9797.69248454183
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 14, disc loss: 0.461127494423184, policy loss: 9474.288667298364
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 15, disc loss: 0.4767855547051461, policy loss: 8059.070592743633
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 16, disc loss: 0.3975251104709315, policy loss: 10484.856929112659
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 17, disc loss: 0.43284075541128875, policy loss: 8211.56303736669
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 18, disc loss: 0.37780141273687534, policy loss: 9567.972132419283
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 1, Iter 19, disc loss: 0.4180223174299016, policy loss: 8073.430396471117
Experience: 2
Using Optimal GP Model. No training being done.
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 0, disc loss: 0.3360373445963355, policy loss: 10190.785551570207
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 1, disc loss: 0.3131421838357269, policy loss: 9938.955815552163
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 2, disc loss: 0.31413993309713023, policy loss: 8232.787138143594
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 3, disc loss: 0.2924604454289682, policy loss: 9342.038377656656
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 4, disc loss: 0.2762138306351079, policy loss: 10100.270668068055
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 5, disc loss: 0.2616369508807235, policy loss: 10124.440453683848
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 6, disc loss: 0.2387638419690768, policy loss: 10239.84904836823
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 7, disc loss: 0.22685635961274242, policy loss: 9936.653246651087
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 8, disc loss: 0.22651570880834793, policy loss: 10231.378930569941
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 9, disc loss: 0.21238148633007825, policy loss: 10199.491173190076
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 10, disc loss: 0.2000989428865013, policy loss: 10776.566227073028
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 11, disc loss: 0.1966082363347111, policy loss: 10385.657366946029
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 12, disc loss: 0.17335100045757337, policy loss: 10833.693679871496
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 13, disc loss: 0.16643636819556848, policy loss: 12526.206960934127
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 14, disc loss: 0.16229775099217836, policy loss: 11164.414948894497
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 15, disc loss: 0.15036677249873448, policy loss: 12170.589785705015
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 16, disc loss: 0.1425663416648506, policy loss: 12057.884954269077
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 17, disc loss: 0.1313203081611792, policy loss: 12441.99974980687
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 18, disc loss: 0.1351508801443151, policy loss: 11128.975986863172
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 2, Iter 19, disc loss: 0.11266229394150198, policy loss: 13152.217349315892
Experience: 3
Using Optimal GP Model. No training being done.
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 0, disc loss: 0.11012383029977701, policy loss: 12639.843033244259
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 1, disc loss: 0.10740358829678688, policy loss: 12830.829599885461
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 2, disc loss: 0.1077036538431855, policy loss: 11170.679342636478
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 3, disc loss: 0.10070078642596755, policy loss: 11382.934417773344
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 4, disc loss: 0.09614034817288435, policy loss: 11816.474112140273
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 5, disc loss: 0.09453590344492166, policy loss: 11373.439958004552
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 6, disc loss: 0.09378184952724945, policy loss: 11537.39082217705
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 7, disc loss: 0.07986362574962308, policy loss: 12691.660293048435
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 8, disc loss: 0.07541268770721615, policy loss: 13039.903535957736
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 9, disc loss: 0.09083403107195938, policy loss: 11408.260664726518
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 10, disc loss: 0.0747692507897299, policy loss: 12418.862288130445
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 11, disc loss: 0.08665038057839358, policy loss: 10076.659357768904
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 12, disc loss: 0.08711651832323478, policy loss: 11242.589757368387
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 13, disc loss: 0.07954628178545439, policy loss: 10850.54396842414
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 14, disc loss: 0.07847210870042419, policy loss: 10476.421550787427
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 15, disc loss: 0.07119654804119982, policy loss: 11038.502558164928
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 16, disc loss: 0.06741940436630516, policy loss: 11432.712194923388
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 17, disc loss: 0.0674679968933579, policy loss: 11731.14256731645
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 18, disc loss: 0.0666994099700737, policy loss: 11637.840909105886
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 3, Iter 19, disc loss: 0.061104928143751264, policy loss: 10957.65158425407
Experience: 4
Using Optimal GP Model. No training being done.
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 4, Iter 0, disc loss: 0.06673726297230585, policy loss: 11504.003553769955
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 4, Iter 1, disc loss: 0.056120630992177366, policy loss: 11986.478740857841
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 4, Iter 2, disc loss: 0.05639302483911153, policy loss: 10545.640522801197
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 4, Iter 3, disc loss: 0.0520220848863444, policy loss: 12175.470619585885
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 4, Iter 4, disc loss: 0.04209273814666223, policy loss: 11876.148021457268
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 4, Iter 5, disc loss: 0.04585350695069213, policy loss: 10967.00182656042
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 4, Iter 6, disc loss: 0.04412287804778645, policy loss: 11627.929915626948
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 4, Iter 7, disc loss: 0.048169931967412344, policy loss: 11467.370995274667
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
j: 7
j: 8
j: 9
Experience 4, Iter 8, disc loss: 0.05954974626632496, policy loss: 11151.454624058924
j: 0
j: 1
j: 2
j: 3
j: 4
j: 5
j: 6
